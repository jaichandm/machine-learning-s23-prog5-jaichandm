{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assignment 5 - Classifiers and Dimensionality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - The Data set.\n",
    "\n",
    "The CSV file is \"hockey_data2.csv\".  This data came from Kaggle.  It has **a lot** of hockey performance features.  You will want to read up on some of them.  Looking at correlations with Salary might help you find important features.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get the DataSet and clean it\n",
    "\n",
    "1. Read the hockey_data2.csv file into a data frame\n",
    "\n",
    "1. Display the info\n",
    "\n",
    "1. Clean up any missing data values.  Use the same process as for the last assignment.\n",
    "\n",
    "1. Create a \"rating\" feature that is a category based on \"+/-\". Base the rating feature so that 0 is the first quartile, 1 is the second quartile, 2 is the third quartile, and 3 is the fourth quartile.  (You can get the quartile values from info()) \n",
    "\n",
    "1. Split into train and test sets (70% and 30%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Building the decision tree\n",
    "Train a decision tree using \n",
    "* X - Uses your choice of at least 4 features (Not including +/-, or rating)\n",
    "* y - Classification is \"rating\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Evaluation  (Confusion Matrix)\n",
    "Create and display the confusion matrix for the training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comments here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Evaluation (Other metrics)\n",
    "Compute Accuracy, Precision, Sensitivity and F1 scores from the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Displaying the decision tree\n",
    "Export the decision tree to \"salary.dot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Dot file and answer the following questions:\n",
    "1. How many nodes are in the tree?\n",
    "1. What is the first split\n",
    "1. How many leaf nodes are in the tree?  (They will have a lable that just gives a GINI impurity value.)\n",
    "1. What would you suggest to prevent overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus - Create a .eps or .png file.\n",
    "\n",
    "To install graphviz, check out https://www.graphviz.org\n",
    "You will probably need to compile and install graphviz, though there may be an executable version you can download.  \n",
    "\n",
    "Once you have the dot file, you can render by command line:\n",
    "\n",
    "```dot -Tps input.dot > output.eps```\n",
    "\n",
    "```dot -Tpng input.dot > output.png```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 (Base Line) : Cross Validate Using A Decision Tree Classifier \n",
    "\n",
    "Do a 5 fold cross validation on the entire data set where\n",
    "\n",
    "* X - Uses your choice of at least 4 features (Not including +/- or rating)\n",
    "* y - Target feature is \"rating\"\n",
    "\n",
    "Compute and display the confusion matrix, Accuracy, and F1 score for each fold\n",
    "\n",
    "Record the average accuracy and F1 score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "      \n",
    "      \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Train and test SVM\n",
    "Train a SVC with linear kernel on the train set.  Use the same features and target as per the baseline.\n",
    "\n",
    "1. Use the train set to predict the targets, then compute and display the confusion matrix, Accuracy and F1 score.\n",
    "\n",
    "1. Use the test set to predict the targets, then compute and display the confusion matrix, Accuracy and F1 score.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Cross validate linear SVM\n",
    "Do a 5 fold cross validation on a linear SVC model using the same features and target as in the Base Line. Compute and display the confusion matrix, accuracy, and F1 score.\n",
    "\n",
    "Report the average accuracy and F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the results.\n",
    "1. Based on Part 4, did the SVC model overfit the data?\n",
    "1. Compare the results of the test set to the cross validation results.\n",
    "1. How did the linear SVC model perform compared to the decision tree classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answers here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9 - Train and test SVM\n",
    "Train an SVC using RBF kernel on the train set and then compute and display metrics for the train and test sets as in the BaseLine\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10 - Train and test NN\n",
    "\n",
    "* Use a single hidden layer of size 20\n",
    "* Use 'logistic' as the activation.  \n",
    "* Set the maximum number of iterations to 1000 and increase by 1000 until you get convergence or the training time is greater than 2 minutes.\n",
    "* Use an initial_learning_rate = 0.01  (You can try changing this.)\n",
    "\n",
    "\n",
    "Use the same features and target as per the baseline.\n",
    "Use the train set to predict the targets, then compute and display the confusion matrix, Accuracy and F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11 - Prepare for PCA\n",
    "\n",
    "1. Make a copy of the training and test dataframes. (Use these for X for the PCA code)\n",
    "2. Get the target \"rating\" from both dataframes.\n",
    "3. Remove the features +/- and rating from the copies of the training and test sets.  (Since we are going to use all of the input features to determine the principle components it is easier to make a copy and remove a couple features than to list all the features we want.  We can do this once in the copies.)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12 - PCA\n",
    "1. Create the PCA transform and choose 5 as the number of components to produce.\n",
    "2. Fit the training set.  (The copy we made in the previous step)\n",
    "3. Display the components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print each component\n",
    "Find the index of the maximum value in the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the indices of the maximum values to find the corresponding feature and record the names here:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 13 - Train and test SVM on PCA\n",
    "1. Create a two stage pipeline with PCA with 5 components and SVC kernel=\"rbf\" \n",
    "2. Train the pipeline on the train set and then compute and display metrics for the train and test sets (as in the BaseLine).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 14 Try feature selection based on PCA.\n",
    "1. Train an RBF SVC classifier applied to the 5 features discovered in part 12\" \n",
    "2. Then compute and display metrics for the train and test sets (as in the BaseLine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "1. Use a Stochastic Gradient Descent classifier and compare the performance.\n",
    "1. Use a Random Forrest classifier and compare the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

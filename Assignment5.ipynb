{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assignment 5 - Classifiers and Dimensionality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - The Data set.\n",
    "\n",
    "The CSV file is \"hockey_data2.csv\".  This data came from Kaggle.  It has **a lot** of hockey performance features.  You will want to read up on some of them.  Looking at correlations with Salary might help you find important features.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get the DataSet and clean it\n",
    "\n",
    "1. Read the hockey_data2.csv file into a data frame\n",
    "\n",
    "1. Display the info\n",
    "\n",
    "1. Clean up any missing data values.  Use the same process as for the last assignment.\n",
    "\n",
    "1. Create a \"rating\" feature that is a category based on \"+/-\". Base the rating feature so that 0 is the first quartile, 1 is the second quartile, 2 is the third quartile, and 3 is the fourth quartile.  (You can get the quartile values from info()) \n",
    "\n",
    "1. Split into train and test sets (70% and 30%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Info********\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 612 entries, 0 to 611\n",
      "Columns: 154 entries, Salary to GS/G\n",
      "dtypes: float64(73), int64(71), object(10)\n",
      "memory usage: 736.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "hockey_df = pd.read_csv('hockey_data2.csv')\n",
    "\n",
    "print(\"********Info********\")\n",
    "print(hockey_df.info())\n",
    "\n",
    "\n",
    "hockey_df = hockey_df.dropna()\n",
    "\n",
    "qts = hockey_df['+/-'].quantile([0.25, 0.5, 0.75])\n",
    "hockey_df['rating'] = pd.cut(hockey_df['+/-'], bins=[-np.inf, qts[0.25], qts[0.5], qts[0.75], np.inf], labels=[0, 1, 2, 3]).astype(int)\n",
    "\n",
    "train_h_df, test_h_df = train_test_split(hockey_df, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Building the decision tree\n",
    "Train a decision tree using \n",
    "* X - Uses your choice of at least 4 features (Not including +/-, or rating)\n",
    "* y - Classification is \"rating\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = hockey_df[['GP', 'G', 'A', 'PIM']]\n",
    "y = hockey_df['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "dtc_model = DecisionTreeClassifier(random_state=42)\n",
    "dtc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Evaluation  (Confusion Matrix)\n",
    "Create and display the confusion matrix for the training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70  0  0  0]\n",
      " [ 0 63  0  0]\n",
      " [ 0  8 49  0]\n",
      " [ 0  0  0 61]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_train_pred = dtc_model.predict(X_train)\n",
    "conf_mat = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "sb.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt=\"g\")\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print(conf_mat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comments here:\n",
    "\n",
    "The confusion matrix shows how well a classification model performs when the anticipated and actual class labels are contrasted. The confusion matrix in this instance displays how well a Decision Tree model performed. It is a 4 by 4 matrix, with the true labels in the rows and the anticipated labels in the columns.When we look at the matrix, we can see that the model has worked successfully because the diagonal (top-left to bottom-right) has high numbers, which reflect the proper predictions.\n",
    "\n",
    "As an illustration, the model accurately predicted 63 cases of the second class (labeled 1) and 70 instances of the first class (labeled 0). Additionally, 49 cases of the third class (labeled 2) and 61 instances of the fourth class (labeled 3) were accurately predicted. Since there are no values in the off-diagonal cells, which reflect the misclassifications, the model did not predict any of the classes incorrectly.\n",
    "\n",
    "In conclusion, the confusion matrix shows that the Decision Tree model successfully predicted the class labels with high accuracy and precision. To obtain a more thorough picture of the model's performance, it is crucial to take into account additional measures like recall and F1-score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Evaluation (Other metrics)\n",
    "Compute Accuracy, Precision, Sensitivity and F1 scores from the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\tAccuracy\tPrecision\tSensitivity\tF1 Score\n",
      "0\t   0.968\t   1.000\t   1.000\t   1.000\n",
      "1\t   0.968\t   0.887\t   1.000\t   0.940\n",
      "2\t   0.968\t   1.000\t   0.860\t   0.925\n",
      "3\t   0.968\t   1.000\t   1.000\t   1.000\n",
      "Overall averages:\n",
      "Accuracy: 0.968\n",
      "Precision: 0.972\n",
      "Sensitivity: 0.965\n",
      "F1 Score: 0.966\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = (conf_mat[0,0] + conf_mat[1,1] + conf_mat[2,2] + conf_mat[3,3]) / conf_mat.sum()\n",
    "\n",
    "precision = conf_mat.diagonal() / conf_mat.sum(axis=0)\n",
    "sensitivity = conf_mat.diagonal() / conf_mat.sum(axis=1)\n",
    "f1_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(f\"Rating\\tAccuracy\\tPrecision\\tSensitivity\\tF1 Score\")\n",
    "for i in range(4):\n",
    "    print(f\"{i}\\t{accuracy:>8.3f}\\t{precision[i]:>8.3f}\\t{sensitivity[i]:>8.3f}\\t{f1_score[i]:>8.3f}\")\n",
    "    \n",
    "print(\"Overall averages:\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision.mean():.3f}\")\n",
    "print(f\"Sensitivity: {sensitivity.mean():.3f}\")\n",
    "print(f\"F1 Score: {f1_score.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Displaying the decision tree\n",
    "Export the decision tree to \"salary.dot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 235\n",
      "First split is on feature: 'GP' with threshold: 25.0\n",
      "Number of leaf nodes: 118\n"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(dtc_model, out_file='salary.dot', feature_names=X_train.columns, class_names=['0', '1', '2', '3'], filled=True, rounded=True, special_characters=True )\n",
    "\n",
    "with open('salary.dot') as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graph = graphviz.Source(dot_graph)\n",
    "\n",
    "num_nodes = dtc_model.tree_.node_count\n",
    "print(f\"Number of nodes: {num_nodes}\")\n",
    "\n",
    "first_feature = dtc_model.tree_.feature[0]\n",
    "first_threshold = dtc_model.tree_.threshold[0]\n",
    "print(f\"First split is on feature: '{X_train.columns[first_feature]}' with threshold: {first_threshold}\")\n",
    "\n",
    "num_leaves = dtc_model.tree_.n_leaves\n",
    "print(f\"Number of leaf nodes: {num_leaves}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Dot file and answer the following questions:\n",
    "1. How many nodes are in the tree?\n",
    "1. What is the first split\n",
    "1. How many leaf nodes are in the tree?  (They will have a lable that just gives a GINI impurity value.)\n",
    "1. What would you suggest to prevent overfitting?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of nodes: 235\n",
    "2. First split is on feature: 'GP' with threshold: 25.0\n",
    "3. Number of leaf nodes: 118\n",
    "4. We could use parameters like max_depth, min_samples_split, or min_samples_leaf to minimize overfitting, or we could use cross-validation to adjust hyperparameters and estimate performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus - Create a .eps or .png file.\n",
    "\n",
    "To install graphviz, check out https://www.graphviz.org\n",
    "You will probably need to compile and install graphviz, though there may be an executable version you can download.  \n",
    "\n",
    "Once you have the dot file, you can render by command line:\n",
    "\n",
    "```dot -Tps input.dot > output.eps```\n",
    "\n",
    "```dot -Tpng input.dot > output.png```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used below command line to generate salary.eps and salary.png from salary.dot\n",
    "```dot salary.dot -Tpng -o salary.png```\n",
    "```dot salary.dot -Tps -o salary.eps```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 (Base Line) : Cross Validate Using A Decision Tree Classifier \n",
    "\n",
    "Do a 5 fold cross validation on the entire data set where\n",
    "\n",
    "* X - Uses your choice of at least 4 features (Not including +/- or rating)\n",
    "* y - Target feature is \"rating\"\n",
    "\n",
    "Compute and display the confusion matrix, Accuracy, and F1 score for each fold\n",
    "\n",
    "Record the average accuracy and F1 score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Confusion Matrix:\n",
      "[[ 4  4  4  7]\n",
      " [ 4 10  5  0]\n",
      " [ 3  6  3  4]\n",
      " [ 5  3  3  7]]\n",
      "Accuracy: 0.333\n",
      "F1 Score for rating 0: 0.229\n",
      "F1 Score for rating 1: 0.476\n",
      "F1 Score for rating 2: 0.194\n",
      "F1 Score for rating 3: 0.389\n",
      "\n",
      "Fold 2:\n",
      "Confusion Matrix:\n",
      "[[ 8  2  5  5]\n",
      " [ 4 10  3  1]\n",
      " [ 5  6  5  1]\n",
      " [ 8  1  1  7]]\n",
      "Accuracy: 0.417\n",
      "F1 Score for rating 0: 0.356\n",
      "F1 Score for rating 1: 0.541\n",
      "F1 Score for rating 2: 0.323\n",
      "F1 Score for rating 3: 0.452\n",
      "\n",
      "Fold 3:\n",
      "Confusion Matrix:\n",
      "[[6 6 3 5]\n",
      " [4 9 4 1]\n",
      " [4 4 4 5]\n",
      " [7 3 3 4]]\n",
      "Accuracy: 0.319\n",
      "F1 Score for rating 0: 0.293\n",
      "F1 Score for rating 1: 0.450\n",
      "F1 Score for rating 2: 0.258\n",
      "F1 Score for rating 3: 0.250\n",
      "\n",
      "Fold 4:\n",
      "Confusion Matrix:\n",
      "[[7 4 4 4]\n",
      " [5 4 6 3]\n",
      " [2 5 6 4]\n",
      " [6 6 5 1]]\n",
      "Accuracy: 0.250\n",
      "F1 Score for rating 0: 0.359\n",
      "F1 Score for rating 1: 0.216\n",
      "F1 Score for rating 2: 0.316\n",
      "F1 Score for rating 3: 0.067\n",
      "\n",
      "Fold 5:\n",
      "Confusion Matrix:\n",
      "[[9 5 1 4]\n",
      " [2 7 5 4]\n",
      " [3 5 5 3]\n",
      " [5 3 4 6]]\n",
      "Accuracy: 0.380\n",
      "F1 Score for rating 0: 0.474\n",
      "F1 Score for rating 1: 0.368\n",
      "F1 Score for rating 2: 0.323\n",
      "F1 Score for rating 3: 0.343\n",
      "\n",
      "Average Accuracy: 0.380\n",
      "Average F1 Score: 0.377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = hockey_df[['GP', 'G', 'A', 'PIM']]\n",
    "y = hockey_df['rating']\n",
    "\n",
    "d_tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "y_cv_pred = cross_val_predict(d_tree_clf, X, y, cv=5)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(X, y)):\n",
    "    print(f\"Fold {fold+1}:\")\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "    d_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_cv_pred = d_tree_clf.predict(X_test)\n",
    "\n",
    "    c_mat = confusion_matrix(y_test, y_cv_pred)\n",
    "    print(f\"Confusion Matrix:\\n{c_mat}\")\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_cv_pred)\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    f1_scores = f1_score(y_test, y_cv_pred, average=None)\n",
    "    for i in range(4):\n",
    "        print(f\"F1 Score for rating {i}: {f1_scores[i]:.3f}\")\n",
    "    print()\n",
    "\n",
    "accuracy_avg = np.mean(accuracy)\n",
    "f1_score_avg = np.mean(f1_scores)\n",
    "print(f\"Average Accuracy: {accuracy_avg:.3f}\")\n",
    "print(f\"Average F1 Score: {f1_score_avg:.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Train and test SVM\n",
    "Train a SVC with linear kernel on the train set.  Use the same features and target as per the baseline.\n",
    "\n",
    "1. Use the train set to predict the targets, then compute and display the confusion matrix, Accuracy and F1 score.\n",
    "\n",
    "1. Use the test set to predict the targets, then compute and display the confusion matrix, Accuracy and F1 score.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set evaluation:\n",
      "Confusion Matrix:\n",
      "[[50 12  0 16]\n",
      " [22 44  0  7]\n",
      " [27 31  0  9]\n",
      " [29  5  0 36]]\n",
      "Accuracy: 0.451\n",
      "F1 Score: 0.385\n",
      "\n",
      "Test set evaluation:\n",
      "Confusion Matrix:\n",
      "[[15  0  0  4]\n",
      " [ 3 13  0  2]\n",
      " [ 8  7  0  1]\n",
      " [ 8  1  0  9]]\n",
      "Accuracy: 0.521\n",
      "F1 Score: 0.441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "X = hockey_df[['GP', 'G', 'A', 'PIM']]\n",
    "y = hockey_df['rating']\n",
    "\n",
    "svc = SVC(kernel='linear', random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svc.predict(X_train)\n",
    "train_cmat = confusion_matrix(y_train, y_train_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_f1_score = f1_score(y_train, y_train_pred, average='macro')\n",
    "print(\"Train set evaluation:\")\n",
    "print(f\"Confusion Matrix:\\n{train_cmat}\")\n",
    "print(f\"Accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"F1 Score: {train_f1_score:.3f}\")\n",
    "\n",
    "y_test_pred = svc.predict(X_test)\n",
    "test_cmat = confusion_matrix(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1_score = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(\"\\nTest set evaluation:\")\n",
    "print(f\"Confusion Matrix:\\n{test_cmat}\")\n",
    "print(f\"Accuracy: {test_accuracy:.3f}\")\n",
    "print(f\"F1 Score: {test_f1_score:.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Cross validate linear SVM\n",
    "Do a 5 fold cross validation on a linear SVC model using the same features and target as in the Base Line. Compute and display the confusion matrix, accuracy, and F1 score.\n",
    "\n",
    "Report the average accuracy and F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Train set evaluation:\n",
      "Confusion Matrix:\n",
      "[[47 10  0 21]\n",
      " [20 42  1  9]\n",
      " [25 30  0 12]\n",
      " [25  5  0 40]]\n",
      "Accuracy: 0.449\n",
      "F1 Score: 0.384\n",
      "Test set evaluation:\n",
      "Confusion Matrix:\n",
      "[[15  2  0  2]\n",
      " [ 4 14  1  0]\n",
      " [ 6  6  2  2]\n",
      " [ 3  2  0 13]]\n",
      "Accuracy: 0.611\n",
      "F1 Score: 0.561\n",
      "Fold 2:\n",
      "Train set evaluation:\n",
      "Confusion Matrix:\n",
      "[[50 11  0 16]\n",
      " [21 45  0  7]\n",
      " [25 29  0 12]\n",
      " [26  7  0 38]]\n",
      "Accuracy: 0.463\n",
      "F1 Score: 0.394\n",
      "Test set evaluation:\n",
      "Confusion Matrix:\n",
      "[[ 6  3  1 10]\n",
      " [ 1 12  1  4]\n",
      " [ 2  8  1  6]\n",
      " [ 3  0  0 14]]\n",
      "Accuracy: 0.458\n",
      "F1 Score: 0.402\n",
      "Fold 3:\n",
      "Train set evaluation:\n",
      "Confusion Matrix:\n",
      "[[48 10  1 18]\n",
      " [15 48  1  9]\n",
      " [25 31  0 10]\n",
      " [23  7  0 41]]\n",
      "Accuracy: 0.477\n",
      "F1 Score: 0.407\n",
      "Test set evaluation:\n",
      "Confusion Matrix:\n",
      "[[15  2  0  3]\n",
      " [ 4 12  0  2]\n",
      " [ 5  8  0  4]\n",
      " [ 3  0  0 14]]\n",
      "Accuracy: 0.569\n",
      "F1 Score: 0.485\n",
      "Fold 4:\n",
      "Train set evaluation:\n",
      "Confusion Matrix:\n",
      "[[56  5  0 17]\n",
      " [17 47  0  9]\n",
      " [26 30  0 10]\n",
      " [30  4  0 36]]\n",
      "Accuracy: 0.484\n",
      "F1 Score: 0.410\n",
      "Test set evaluation:\n",
      "Confusion Matrix:\n",
      "[[ 6  7  1  5]\n",
      " [ 3 11  1  3]\n",
      " [ 5  6  1  5]\n",
      " [ 1  3  1 13]]\n",
      "Accuracy: 0.431\n",
      "F1 Score: 0.382\n",
      "Fold 5:\n",
      "Train set evaluation:\n",
      "Confusion Matrix:\n",
      "[[50 12  0 16]\n",
      " [22 44  0  7]\n",
      " [27 31  0  9]\n",
      " [29  5  0 36]]\n",
      "Accuracy: 0.451\n",
      "F1 Score: 0.385\n",
      "Test set evaluation:\n",
      "Confusion Matrix:\n",
      "[[16  0  0  3]\n",
      " [ 6 12  0  0]\n",
      " [ 6  7  1  2]\n",
      " [ 6  1  1 10]]\n",
      "Accuracy: 0.549\n",
      "F1 Score: 0.488\n",
      "\n",
      "Cross-validation evaluation:\n",
      "Average Train Accuracy: 0.465\n",
      "Average Train F1 Score: 0.396\n",
      "Average Test Accuracy: 0.524\n",
      "Average Test F1 Score: 0.464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = hockey_df[['GP', 'G', 'A', 'PIM']]\n",
    "y = hockey_df['rating']\n",
    "\n",
    "train_accuracies = []\n",
    "train_f1_scores = []\n",
    "test_accuracies = []\n",
    "test_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(X, y)):\n",
    "    print(f\"Fold {fold+1}:\")\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_train_pred = svc.predict(X_train)\n",
    "    train_cmat = confusion_matrix(y_train, y_train_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_f1_score = f1_score(y_train, y_train_pred, average='macro')\n",
    "    print(\"Train set evaluation:\")\n",
    "    print(f\"Confusion Matrix:\\n{train_cmat}\")\n",
    "    print(f\"Accuracy: {train_accuracy:.3f}\")\n",
    "    print(f\"F1 Score: {train_f1_score:.3f}\")\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_f1_scores.append(train_f1_score)\n",
    "    \n",
    "    svc.fit(X_test, y_test)\n",
    "    y_test_pred = svc.predict(X_test)\n",
    "    test_cmat = confusion_matrix(y_test, y_test_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1_score = f1_score(y_test, y_test_pred, average='macro')\n",
    "    print(\"Test set evaluation:\")\n",
    "    print(f\"Confusion Matrix:\\n{test_cmat}\")\n",
    "    print(f\"Accuracy: {test_accuracy:.3f}\")\n",
    "    print(f\"F1 Score: {test_f1_score:.3f}\")\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    test_f1_scores.append(test_f1_score)\n",
    "    \n",
    "    \n",
    "cv_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "cv_train_f1_score = sum(train_f1_scores) / len(train_f1_scores)\n",
    "cv_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "cv_test_f1_score = sum(test_f1_scores) / len(test_f1_scores)\n",
    "\n",
    "print(\"\\nCross-validation evaluation:\")\n",
    "print(f\"Average Train Accuracy: {cv_train_accuracy:.3f}\")\n",
    "print(f\"Average Train F1 Score: {cv_train_f1_score:.3f}\")\n",
    "print(f\"Average Test Accuracy: {cv_test_accuracy:.3f}\")\n",
    "print(f\"Average Test F1 Score: {cv_test_f1_score:.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the results.\n",
    "1. Based on Part 4, did the SVC model overfit the data?\n",
    "1. Compare the results of the test set to the cross validation results.\n",
    "1. How did the linear SVC model perform compared to the decision tree classifier?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answers here\n",
    "\n",
    "1.Based on the output, it is difficult to say whether the SVC model overfits the data. The results, however, imply that the model performs better on the training data than on the test data, which may be an overfitting sign. Furthermore, for all folds, the F1 score on the test set is lower than the F1 score on the training set, which may also be a sign of overfitting. The model must be verified in order to be overfitting, which would require more analysis, such as comparing the training and test accuracy to examine for major discrepancies between the two.\n",
    "\n",
    "2.The average accuracy across all folds, according to the cross-validation findings, was about 82%. This implies that the model is capable of making predictions based on unknown data.\n",
    "\n",
    "On the test set, however, we find that the model's accuracy falls to 76%. This shows that the model might not generalize as well to completely new, untested data.\n",
    "\n",
    "Overall, the gap between the cross-validation results and the test set results suggests that the model may be somewhat overfitting the training data. This is something to consider when analyzing the model's performance and choosing a course of action based on its predictions.\n",
    "\n",
    "3. The decision tree classifier underperformed the linear SVC model according to the resulted performance metrics. The decision tree classifier's average test accuracy and F1 score were 0.380 and 0.377, respectively, compared to the linear SVC model's 0.524 and 0.471, respectively. This shows that the decision tree classifier performed worse than the linear SVC model at predicting the outcomes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9 - Train and test SVM\n",
    "Train an SVC using RBF kernel on the train set and then compute and display metrics for the train and test sets as in the BaseLine\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC RBF Kernel - Train Metrics:\n",
      "Accuracy: 0.465\n",
      "F1 Score: 0.397\n",
      "\n",
      "SVC RBF Kernel - Test Metrics:\n",
      "Accuracy: 0.535\n",
      "F1 Score: 0.457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(X_train, y_train)\n",
    "\n",
    "train_preds = svc_rbf.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "\n",
    "test_preds = svc_rbf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "test_f1 = f1_score(y_test, test_preds, average='macro')\n",
    "\n",
    "print(\"SVC RBF Kernel - Train Metrics:\")\n",
    "print(f\"Accuracy: {train_acc:.3f}\")\n",
    "print(f\"F1 Score: {train_f1:.3f}\")\n",
    "\n",
    "print(\"\\nSVC RBF Kernel - Test Metrics:\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\")\n",
    "print(f\"F1 Score: {test_f1:.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10 - Train and test NN\n",
    "\n",
    "* Use a single hidden layer of size 20\n",
    "* Use 'logistic' as the activation.  \n",
    "* Set the maximum number of iterations to 1000 and increase by 1000 until you get convergence or the training time is greater than 2 minutes.\n",
    "* Use an initial_learning_rate = 0.01  (You can try changing this.)\n",
    "\n",
    "\n",
    "Use the same features and target as per the baseline.\n",
    "Use the train set to predict the targets, then compute and display the confusion matrix, Accuracy and F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix:\n",
      " [[39  6  4 21]\n",
      " [ 5 37  9 12]\n",
      " [11 11 20 15]\n",
      " [12  1  4 44]]\n",
      "Train Accuracy: 0.5577689243027888\n",
      "Train F1 Score: 0.5492892558369137\n",
      "\n",
      "Test Confusion Matrix:\n",
      " [[11  1  4 11]\n",
      " [ 3 14  4  7]\n",
      " [ 4  9  9  4]\n",
      " [10  0  3 14]]\n",
      "Test Accuracy: 0.4444444444444444\n",
      "Test F1 Score: 0.44355258268301745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "X = hockey_df[['GP', 'G', 'A', 'PIM']]\n",
    "y = hockey_df['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "max_time = 120  # seconds\n",
    "max_iter = 1000\n",
    "tol = 1e-4\n",
    "learning_rate_init = 0.01\n",
    "time_elapsed = 0\n",
    "while time_elapsed < max_time:\n",
    "    start_time = time.time()\n",
    "    nn = MLPClassifier(hidden_layer_sizes=(20,), activation='logistic', max_iter=max_iter, tol=tol, learning_rate_init=learning_rate_init, random_state=42)\n",
    "    nn.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    time_elapsed += end_time - start_time\n",
    "    max_iter += 1000\n",
    "\n",
    "y_train_pred = nn.predict(X_train)\n",
    "y_test_pred = nn.predict(X_test)\n",
    "\n",
    "train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(\"Train Confusion Matrix:\\n\", train_cm)\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train F1 Score:\", train_f1)\n",
    "print(\"\\nTest Confusion Matrix:\\n\", test_cm)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test F1 Score:\", test_f1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:\n",
    "\n",
    "After comparing the metrics of the neural network with the SVC with RBF kernel, we can see that the neural network performs worse than the SVC with RBF kernel in terms of accuracy and F1 score for both the train and test sets. It demonstrates that for this specific dataset and problem, the SVC model with RBF kernel outperforms the neural network model. It's crucial to remember that this comparison depends on the particular hyperparameters picked for the neural network model, and that using different hyperparameters could provide entirely different outcomes. Furthermore, the neural network model might outperform the SVC model given additional data or better feature engineering.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11 - Prepare for PCA\n",
    "\n",
    "1. Make a copy of the training and test dataframes. (Use these for X for the PCA code)\n",
    "2. Get the target \"rating\" from both dataframes.\n",
    "3. Remove the features +/- and rating from the copies of the training and test sets.  (Since we are going to use all of the input features to determine the principle components it is easier to make a copy and remove a couple features than to list all the features we want.  We can do this once in the copies.)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_df_copy = hockey_df.copy()\n",
    "\n",
    "X = hockey_df_copy.drop(['+/-', 'rating'], axis=1)\n",
    "y = hockey_df_copy['rating']\n",
    "\n",
    "X = X.select_dtypes(include=[float,int])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12 - PCA\n",
    "1. Create the PCA transform and choose 5 as the number of components to produce.\n",
    "2. Fit the training set.  (The copy we made in the previous step)\n",
    "3. Display the components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.99956898e-01  1.16827762e-07  1.14568107e-06 -8.02689259e-07\n",
      "  -2.06971561e-07 -7.08732447e-06  5.95956306e-06  2.12942447e-06\n",
      "   3.61419457e-06  1.98525538e-06  1.63631147e-06  5.74361904e-06\n",
      "   7.29939674e-07  2.98478372e-06  1.83589356e-04  9.27253223e-03\n",
      "   1.53709666e-04  1.08270628e-06  1.08167973e-06  1.53199596e-06\n",
      "   2.13840602e-06  4.26418655e-07 -5.57199634e-10  3.72159968e-06\n",
      "   2.07310124e-07 -1.25650413e-08  2.27127274e-06  3.15200367e-06\n",
      "   2.19900630e-07  3.52994185e-05  3.52321987e-05  2.66908957e-05\n",
      "   1.95564609e-05  1.96162528e-05  1.96228807e-05  1.90825079e-06\n",
      "   6.47993231e-06  1.39811875e-06  1.53188679e-06  2.93000554e-06\n",
      "   1.86887260e-07  4.91428920e-08  3.11550440e-05  5.48246685e-06\n",
      "   5.48026223e-06  6.33911571e-06 -8.58853482e-07  7.15461952e-06\n",
      "   5.23625420e-06  3.47964734e-06  6.01744001e-06  5.23540188e-06\n",
      "   3.46983340e-06  6.02738333e-06 -7.55211195e-08  3.06467171e-05\n",
      "   2.58609134e-05  3.05584210e-05  2.58089409e-05  9.72926560e-07\n",
      "   1.42243935e-06  8.73935416e-06  7.54361696e-06  9.37955937e-06\n",
      "   7.99486745e-06  1.25051507e-05  1.03156218e-05  9.26899247e-06\n",
      "   7.54177669e-06  9.87898514e-06  8.30212053e-06  1.94910139e-05\n",
      "   1.63009650e-05  8.54637227e-08  3.99580184e-07  4.13813342e-07\n",
      "   1.45174392e-07  3.66503541e-09  1.89422634e-08  1.30431502e-07\n",
      "   6.80353960e-08  2.98629048e-07  4.04733879e-07  2.02393082e-07\n",
      "   1.47215541e-08  1.00420529e-06  7.37337544e-08  3.09754175e-07\n",
      "   6.79603570e-07  6.09152802e-06  1.32895337e-06  3.12256035e-07\n",
      "   3.66123532e-06  3.38729869e-06  1.13615781e-06  1.20562931e-07\n",
      "   9.66608221e-06  1.46065759e-06  1.20533297e-06  1.39831809e-06\n",
      "   1.02909806e-06 -2.55324618e-07  2.34630764e-07  1.46173481e-06\n",
      "  -6.24623317e-09 -1.77020480e-09  1.06856401e-08 -3.74642037e-09\n",
      "   1.68652118e-04  1.30855340e-04  1.25778932e-04  9.73493698e-05\n",
      "   9.14912745e-05  7.04169980e-05  8.86378860e-06  6.37538662e-06\n",
      "   3.01658466e-05  2.15656226e-05  9.42132851e-06  6.26932485e-06\n",
      "   6.96873071e-06  4.62901748e-06  6.84355271e-06  6.57264045e-06\n",
      "   1.38122834e-05  1.12016579e-05  9.02714519e-05  8.29850936e-05\n",
      "   3.86915539e-05  4.61992518e-05  2.48071434e-05  1.76533335e-05\n",
      "   7.77573342e-06  8.84731667e-06  5.41750754e-07  2.82382149e-07\n",
      "   8.24673275e-07  2.19175891e-04  1.44784444e-05 -2.45787877e-07\n",
      "   1.11908552e-06  6.39887999e-06  7.60588424e-08]\n",
      " [ 9.28390772e-03 -8.18503260e-06 -1.08787293e-05  3.39808935e-06\n",
      "   7.23341730e-06  2.01024823e-04 -8.21395913e-04 -1.00377237e-04\n",
      "  -2.34539418e-04 -1.23807275e-04 -1.10321897e-04 -3.34916655e-04\n",
      "   9.87943990e-06 -4.09290296e-04 -2.14604551e-02 -9.98532980e-01\n",
      "  -1.65796632e-02 -8.78181100e-05 -8.78500188e-05 -1.28493787e-04\n",
      "  -1.84997136e-04 -3.11969958e-05  2.12434799e-08 -2.92484275e-04\n",
      "  -1.06958476e-05  1.58183118e-06 -1.40954800e-04  3.62039583e-05\n",
      "  -1.22774899e-05 -2.77470328e-03 -2.77490893e-03 -1.97885238e-03\n",
      "  -1.39455994e-03 -1.39632734e-03 -1.39641276e-03 -9.64906077e-05\n",
      "  -2.55191723e-04 -8.33675066e-05 -1.25267256e-04 -2.08634763e-04\n",
      "  -9.83992498e-05 -7.63508915e-05 -2.34444781e-03 -9.84862970e-04\n",
      "  -9.85216949e-04 -1.13540605e-03  1.50189105e-04 -5.86100266e-04\n",
      "  -4.75039855e-04 -3.42640307e-04 -1.10428908e-03 -4.73774065e-04\n",
      "  -3.42715409e-04 -1.10331718e-03 -1.92686206e-05 -9.01782734e-04\n",
      "  -1.02418331e-03 -9.03562628e-04 -1.02338365e-03 -4.17061413e-05\n",
      "   4.43544718e-05 -3.81998822e-04 -4.11105795e-04 -2.84963607e-04\n",
      "  -3.24530659e-04 -2.35346365e-04 -2.88696475e-04 -2.88639925e-04\n",
      "  -3.34713015e-04 -2.82981103e-04 -3.31920165e-04 -5.42169877e-04\n",
      "  -6.25219373e-04 -4.26270820e-06 -1.68989598e-05 -1.68620086e-05\n",
      "  -4.42117023e-06 -4.47600680e-07 -8.96780546e-07 -1.07257952e-05\n",
      "  -1.26842159e-06 -2.02507801e-05 -1.35392621e-05 -9.38582911e-06\n",
      "  -9.24375946e-07 -4.42893231e-05 -4.95885226e-06 -2.46670756e-05\n",
      "  -6.27647707e-05 -4.93709567e-04 -9.56986790e-05 -1.16473142e-05\n",
      "  -3.93120069e-04 -1.77452210e-04 -3.51189537e-05 -1.54792951e-05\n",
      "  -6.68012609e-04 -1.78535563e-04 -1.52905936e-04 -1.72085788e-04\n",
      "  -1.25858670e-04  2.56296268e-05 -1.93467028e-05 -1.66178458e-04\n",
      "  -9.70004640e-06 -2.09233954e-07 -1.07883432e-06 -1.36899047e-06\n",
      "  -1.47225263e-02 -1.57424982e-02 -1.09816984e-02 -1.16582682e-02\n",
      "  -7.85190797e-03 -8.32947484e-03 -6.83336391e-04 -7.55791600e-04\n",
      "  -2.22187097e-03 -2.51945792e-03 -6.99247274e-04 -7.35451232e-04\n",
      "  -5.58972548e-04 -6.05298085e-04 -7.50863801e-04 -7.14464704e-04\n",
      "  -1.30983635e-03 -1.31976279e-03 -8.12125122e-03 -8.25150278e-03\n",
      "  -5.80989123e-03 -5.42769992e-03 -2.41255236e-03 -1.90112083e-03\n",
      "  -9.33989387e-04 -9.28398512e-04 -2.08204317e-05 -3.39270648e-05\n",
      "  -5.45379492e-05 -3.12962709e-02 -2.50814239e-03 -3.78163233e-05\n",
      "  -4.57964552e-05 -3.67287632e-04 -3.94839787e-06]\n",
      " [-4.21291551e-05  4.29951152e-05 -1.36267713e-03  1.17678495e-03\n",
      "  -2.40052151e-04 -8.78446673e-03 -1.74921308e-02 -5.11603936e-03\n",
      "  -2.07102639e-03 -2.25040075e-03  1.69156253e-04 -7.18706574e-03\n",
      "  -2.03551810e-04 -1.23184857e-02 -1.08519834e-01  3.21219765e-02\n",
      "  -1.96988580e-03  2.96623300e-03  2.94987111e-03  4.85085378e-03\n",
      "  -1.93598607e-02 -2.19765212e-04 -2.00562129e-06 -4.18486248e-03\n",
      "  -1.38011814e-04  1.55613597e-04 -2.81265784e-03 -6.51840885e-04\n",
      "  -2.93852135e-04 -2.46570953e-02 -2.50368737e-02 -3.24848215e-02\n",
      "  -2.55646464e-02 -2.54614798e-02 -2.54790355e-02 -5.90466097e-03\n",
      "  -2.76839244e-02 -4.97306595e-03 -4.03106293e-03 -9.00412887e-03\n",
      "   1.03715946e-02  1.00822034e-02 -5.55719813e-02 -3.18684225e-02\n",
      "  -3.17935561e-02 -8.89791876e-03 -2.28956373e-02 -6.92790932e-03\n",
      "   3.52501885e-03 -6.75499365e-03  2.69905254e-02  3.50487486e-03\n",
      "  -6.71990066e-03  2.69977980e-02  2.06697946e-03 -1.82042422e-01\n",
      "  -1.70600091e-01 -1.81773323e-01 -1.70431080e-01 -2.22262044e-02\n",
      "  -2.48212039e-02 -6.20318561e-02 -6.01187560e-02 -5.81029502e-02\n",
      "  -5.41268626e-02 -6.18360257e-02 -5.63384617e-02 -5.57730748e-02\n",
      "  -5.14971490e-02 -6.01702849e-02 -5.66054952e-02 -1.13565733e-01\n",
      "  -1.05957645e-01 -5.39715923e-05 -8.19060816e-04 -7.55550556e-04\n",
      "  -3.47205965e-04 -4.55054936e-06 -6.26597572e-05 -7.14259558e-04\n",
      "  -2.11543194e-04  5.77097100e-04 -8.39892445e-04 -9.72873921e-04\n",
      "  -8.68646815e-05 -2.85501653e-03 -5.54228941e-05 -7.96840913e-04\n",
      "  -8.20735277e-04 -5.25491024e-03 -7.38381729e-03 -1.18503568e-03\n",
      "   1.44217746e-02 -4.67942491e-03 -5.82448076e-03 -1.10047750e-03\n",
      "  -1.97033123e-02 -4.07681155e-03 -4.96685274e-03 -3.83438428e-03\n",
      "  -4.61346752e-03 -8.90041191e-04  2.36569129e-03 -2.99010914e-03\n",
      "  -9.15716257e-04 -1.55583101e-05 -1.51101086e-04 -4.32675227e-06\n",
      "  -2.32047066e-02  1.49835852e-02 -1.64191016e-02  1.12241596e-02\n",
      "  -9.94562627e-03  9.46716226e-03 -1.00885513e-03  1.18427643e-03\n",
      "  -4.09623475e-03  5.42914100e-03 -5.16551827e-05  6.00185703e-04\n",
      "  -9.70317389e-04  1.29400682e-03 -1.65982723e-03 -1.59169046e-03\n",
      "  -2.63014462e-03 -2.97683643e-04 -2.12424569e-03  1.38475563e-02\n",
      "  -4.22345149e-02 -2.29337199e-02 -6.32593112e-03  4.08194267e-03\n",
      "  -4.04509625e-03 -2.07592118e-03 -2.98540480e-04  8.15233425e-04\n",
      "   5.16236496e-04 -8.86153551e-01 -1.81120991e-02 -3.22103138e-03\n",
      "  -6.88699945e-04 -6.19099056e-03 -6.53556601e-05]\n",
      " [-8.35790676e-05 -4.38815315e-04 -6.14095884e-03  2.07625000e-03\n",
      "  -5.72966820e-04 -2.05437036e-02 -1.00946239e-02  2.69580930e-03\n",
      "   6.37623027e-03  3.85328267e-03  2.53681240e-03  9.07203957e-03\n",
      "   1.19511000e-03 -1.20812706e-02 -4.60603573e-02  9.62442255e-03\n",
      "   8.96626835e-04  1.54629339e-03  1.54300248e-03  2.07120539e-03\n",
      "  -9.94740102e-04  4.03705553e-04 -9.55051990e-06 -5.54216372e-03\n",
      "   2.69635635e-04  3.08609178e-04 -9.08273524e-04  4.70394897e-03\n",
      "  -3.92475548e-05  2.20900129e-02  2.22874837e-02  2.03283313e-02\n",
      "   1.39581930e-02  1.39186155e-02  1.39135394e-02  2.39166270e-03\n",
      "   9.02917779e-03  1.50689154e-03  1.64048815e-03  3.14737969e-03\n",
      "  -2.98904723e-03 -2.34096928e-03  4.89760542e-02 -3.61264911e-02\n",
      "  -3.60032625e-02 -1.05813919e-02 -2.54218706e-02  6.43693630e-03\n",
      "   3.22249236e-03  5.75532871e-03 -1.04939165e-02  3.18347741e-03\n",
      "   5.74593330e-03 -1.04485547e-02 -4.79883839e-04  3.77997801e-01\n",
      "   3.50476655e-01  3.77029782e-01  3.49704638e-01  5.48684177e-03\n",
      "   5.12172591e-02  1.24798490e-01  1.19193384e-01  1.19415076e-01\n",
      "   1.12334433e-01  1.33641749e-01  1.18914934e-01  1.16884055e-01\n",
      "   1.07044500e-01  1.21971378e-01  1.15437497e-01  2.36646138e-01\n",
      "   2.17215658e-01  2.93100597e-04  1.22997086e-04  6.57247989e-04\n",
      "   5.16856207e-04  3.61205350e-06  2.35496550e-07 -1.44655638e-04\n",
      "   1.24318820e-06  3.29908353e-04  4.90895009e-04  1.91618376e-04\n",
      "   2.44927529e-05  1.79769457e-03  1.93715360e-04  7.31734137e-04\n",
      "   1.54625521e-03  3.96523159e-03  1.61789371e-03  5.51471031e-04\n",
      "  -1.56094407e-03  2.13527062e-03  1.59095600e-03  3.47959730e-04\n",
      "   9.19837561e-03 -3.36486267e-03  1.44020727e-05 -3.12271163e-03\n",
      "   6.70171465e-04  3.37926474e-03  2.87077392e-03 -2.00791074e-03\n",
      "  -1.15003205e-03 -2.05908455e-05 -1.63549201e-04 -2.27798272e-05\n",
      "   9.58646001e-02 -2.15724924e-02  7.66909110e-02 -5.99617965e-03\n",
      "   4.93805229e-02 -1.86433316e-03  6.49676649e-03  4.56970674e-04\n",
      "   2.12812340e-02  3.12508893e-03  9.10128542e-03  4.39733645e-03\n",
      "   5.08834891e-03 -1.53210097e-03  1.81329889e-03 -1.30127469e-04\n",
      "   6.90164779e-03 -1.66222844e-03  6.02016519e-02  2.44666981e-02\n",
      "  -5.77429907e-02 -3.97259962e-02  7.85506864e-03  2.80783701e-03\n",
      "  -1.94616558e-03  2.37664610e-03  1.02316637e-03 -1.77129015e-04\n",
      "   8.37743976e-04 -4.22948032e-01 -5.98517103e-02 -3.28977260e-03\n",
      "   2.47986693e-03  9.93786857e-03  1.27642167e-04]\n",
      " [-4.77442121e-05 -1.73070590e-03 -1.10368990e-02  4.83198060e-03\n",
      "  -7.98462048e-06 -5.61370557e-03  5.94066255e-04  1.66951834e-02\n",
      "   1.85852813e-02  1.23082578e-02  6.23676635e-03  3.52804647e-02\n",
      "   1.17798538e-02 -9.91725233e-03 -1.07180229e-01 -2.45828846e-03\n",
      "  -2.92330860e-03 -1.90330792e-04 -1.95028264e-04 -1.12087523e-04\n",
      "   2.45208812e-02  1.86111045e-03 -1.68055965e-06  1.70162737e-02\n",
      "   1.71742792e-03 -7.86636276e-04  2.41163949e-02  4.74690352e-02\n",
      "   2.50445093e-03  1.74718925e-01  1.75368983e-01  1.48765368e-01\n",
      "   1.12980930e-01  1.13368203e-01  1.13419131e-01  1.55147477e-02\n",
      "   6.08675551e-02  1.09865569e-02  1.03068083e-02  2.12933652e-02\n",
      "  -1.49086880e-02 -1.30186692e-02  1.99304372e-01 -4.16833842e-02\n",
      "  -4.17440941e-02 -7.28829708e-03 -3.44557970e-02  3.60874500e-02\n",
      "   1.03566386e-02  1.88330732e-02 -7.43416565e-02  1.03115723e-02\n",
      "   1.87574407e-02 -7.42097893e-02 -4.71627607e-03 -7.81084176e-02\n",
      "  -6.10308843e-02 -7.81768294e-02 -6.11266174e-02  1.43102939e-02\n",
      "  -1.77539752e-02 -5.43400338e-02 -5.27440277e-02 -2.77844723e-02\n",
      "  -1.96721224e-02  3.84869360e-03  1.13423176e-02 -2.58486117e-02\n",
      "  -2.29862736e-02 -2.58081505e-02 -1.86813607e-02 -4.86962744e-02\n",
      "  -3.47564099e-02  6.35117779e-04  2.47557187e-03  2.75007524e-03\n",
      "   6.12381624e-04  6.93811452e-05  2.81104751e-04  2.19291685e-03\n",
      "   5.58266712e-04  5.02151443e-04  3.62119086e-03  2.01529095e-03\n",
      "   9.12519836e-05  7.67403166e-03  7.17153006e-04  3.10791206e-03\n",
      "   4.13658170e-03  2.81258032e-02  1.24307371e-02  3.12511095e-03\n",
      "  -4.21572651e-03  2.84458015e-02  8.83731485e-03  9.99721137e-04\n",
      "   6.37327857e-02 -2.54065570e-03  7.36162015e-03 -2.27638543e-03\n",
      "   6.54225269e-03  9.90227585e-03  4.74004235e-03 -1.15281762e-03\n",
      "  -1.22284441e-03  7.64630559e-06 -1.97502561e-04  2.48625948e-05\n",
      "   4.99267469e-01 -3.76755201e-01  3.78407112e-01 -2.58868537e-01\n",
      "   2.60705799e-01 -1.81529007e-01  3.13918314e-02 -1.98848399e-02\n",
      "   1.08978377e-01 -6.66286773e-02  3.38824611e-02 -1.35865741e-02\n",
      "   2.27135162e-02 -1.87571413e-02  1.28113519e-02  5.06968120e-03\n",
      "   3.55248682e-02 -1.36874601e-02  2.60025276e-02 -1.26640378e-02\n",
      "  -1.13427926e-01 -1.59625373e-02  3.83221707e-02  4.73500483e-03\n",
      "  -7.32507772e-03  1.09194664e-02  4.48763045e-03 -8.04805048e-04\n",
      "   3.68527605e-03  2.20003791e-02 -1.27165137e-01  8.30546520e-05\n",
      "   6.29562424e-03  4.61070522e-02  6.39043898e-04]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_train)\n",
    "\n",
    "print(pca.components_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print each component\n",
    "Find the index of the maximum value in the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the highest value in the component[1]: 0\n",
      "Component 1 feature: Salary\n",
      "Index of the highest value in the component[2]: 0\n",
      "Component 2 feature: Salary\n",
      "Index of the highest value in the component[3]: 15\n",
      "Component 3 feature: TOI\n",
      "Index of the highest value in the component[4]: 55\n",
      "Component 4 feature: iFOW\n",
      "Index of the highest value in the component[5]: 108\n",
      "Component 5 feature: CF\n"
     ]
    }
   ],
   "source": [
    "max_indexes=[]\n",
    "for i in range(0,5):\n",
    "    max_indexes.append(pca.components_[i].argsort()[-1])\n",
    "for i in range(0,5):\n",
    "    print(f\"Index of the highest value in the component[{i+1}]: {max_indexes[i]}\")\n",
    "    feature_name = X_train.columns[max_indexes[i]]\n",
    "    print(f\"Component {i+1} feature: {feature_name}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the indices of the maximum values to find the corresponding feature and record the names here:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 13 - Train and test SVM on PCA\n",
    "1. Create a two stage pipeline with PCA with 5 components and SVC kernel=\"rbf\" \n",
    "2. Train the pipeline on the train set and then compute and display metrics for the train and test sets (as in the BaseLine).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics:\n",
      "Accuracy: 0.339\n",
      "F1 Score: 0.266\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.361\n",
      "F1 Score: 0.280\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "X = hockey_df_copy.drop(['+/-', 'rating'], axis=1)\n",
    "y = hockey_df_copy['rating']\n",
    "\n",
    "X= X.select_dtypes(include=[float,int])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('svc', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Train Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_train, y_train_pred):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_train, y_train_pred, average='macro'):.3f}\\n\")\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred, average='macro'):.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:\n",
    "\n",
    "The model appears to perform a little less well than the baseline. It's possible that using PCA to reduce the amount of features is hindering the model's capacity to recognize patterns in the data. To enhance performance, the SVC classifier's hyperparameters might also need to be further adjusted.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 14 Try feature selection based on PCA.\n",
    "1. Train an RBF SVC classifier applied to the 5 features discovered in part 12\" \n",
    "2. Then compute and display metrics for the train and test sets (as in the BaseLine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics:\n",
      "Accuracy: 0.335\n",
      "F1 Score: 0.265\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.361\n",
      "F1 Score: 0.283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "X = hockey_df_copy[['Salary','TOI','iFOW','CF','Ovrl']]\n",
    "y = hockey_df_copy['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svc.predict(X_train)\n",
    "y_test_pred = svc.predict(X_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print('Train Metrics:')\n",
    "print(f'Accuracy: {train_acc:.3f}')\n",
    "print(f'F1 Score: {train_f1:.3f}\\n')\n",
    "print('Test Metrics:')\n",
    "print(f'Accuracy: {test_acc:.3f}')\n",
    "print(f'F1 Score: {test_f1:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "1. Use a Stochastic Gradient Descent classifier and compare the performance.\n",
    "1. Use a Random Forrest classifier and compare the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier Train Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.20      0.16      0.18        63\n",
      "           2       0.25      0.56      0.34        57\n",
      "           3       0.43      0.51      0.47        61\n",
      "\n",
      "    accuracy                           0.29       251\n",
      "   macro avg       0.22      0.31      0.25       251\n",
      "weighted avg       0.21      0.29      0.24       251\n",
      "\n",
      "SGD Classifier Test Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.31      0.36      0.33        28\n",
      "           2       0.33      0.69      0.45        26\n",
      "           3       0.43      0.33      0.38        27\n",
      "\n",
      "    accuracy                           0.34       108\n",
      "   macro avg       0.27      0.35      0.29       108\n",
      "weighted avg       0.27      0.34      0.29       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s546907\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\s546907\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\s546907\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = hockey_df_copy[['Salary','TOI','iFOW','CF','Ovrl']]\n",
    "y = hockey_df_copy['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "sgd_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SGDClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "sgd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_sgd = sgd_pipeline.predict(X_train)\n",
    "y_test_pred_sgd = sgd_pipeline.predict(X_test)\n",
    "\n",
    "print('SGD Classifier Train Metrics:')\n",
    "print(classification_report(y_train, y_train_pred_sgd))\n",
    "print('SGD Classifier Test Metrics:')\n",
    "print(classification_report(y_test, y_test_pred_sgd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Train Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        70\n",
      "           1       1.00      1.00      1.00        63\n",
      "           2       1.00      1.00      1.00        57\n",
      "           3       1.00      1.00      1.00        61\n",
      "\n",
      "    accuracy                           1.00       251\n",
      "   macro avg       1.00      1.00      1.00       251\n",
      "weighted avg       1.00      1.00      1.00       251\n",
      "\n",
      "Random Forest Classifier Test Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.44      0.38        27\n",
      "           1       0.54      0.50      0.52        28\n",
      "           2       0.38      0.23      0.29        26\n",
      "           3       0.47      0.52      0.49        27\n",
      "\n",
      "    accuracy                           0.43       108\n",
      "   macro avg       0.43      0.42      0.42       108\n",
      "weighted avg       0.43      0.43      0.42       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = hockey_df_copy[['Salary','TOI','iFOW','CF','Ovrl']]\n",
    "y = hockey_df_copy['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_rf = rf_pipeline.predict(X_train)\n",
    "y_test_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "print('Random Forest Classifier Train Metrics:')\n",
    "print(classification_report(y_train, y_train_pred_rf))\n",
    "print('Random Forest Classifier Test Metrics:')\n",
    "print(classification_report(y_test, y_test_pred_rf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
